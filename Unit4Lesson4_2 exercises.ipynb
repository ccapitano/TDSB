{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import sklearn\n",
    "import spacy\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "from nltk.corpus import gutenberg, stopwords\n",
    "from collections import Counter\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility function for standard text cleaning.\n",
    "def text_cleaner(text):\n",
    "    # Visual inspection identifies a form of punctuation spaCy does not\n",
    "    # recognize: the double dash '--'.  Better get rid of it now!\n",
    "    text = re.sub(r'--',' ',text)\n",
    "    text = re.sub(\"[\\[].*?[\\]]\", \"\", text)\n",
    "    text = ' '.join(text.split())\n",
    "    return text\n",
    "    \n",
    "# Load and clean the data.\n",
    "persuasion = gutenberg.raw('austen-persuasion.txt')\n",
    "alice = gutenberg.raw('carroll-alice.txt')\n",
    "milton = gutenberg.raw('milton-paradise.txt')\n",
    "sense = gutenberg.raw('austen-sense.txt')\n",
    "\n",
    "# The Chapter indicator is idiosyncratic\n",
    "persuasion = re.sub(r'Chapter \\d+', '', persuasion)\n",
    "sense = re.sub(r'Chapter \\d+', '', sense)\n",
    "alice = re.sub(r'CHAPTER .*', '', alice)\n",
    "milton = re.sub(r'Book \\d+', '', milton)\n",
    "    \n",
    "alice = text_cleaner(alice[:int(len(alice)/10)])\n",
    "persuasion = text_cleaner(persuasion[:int(len(persuasion)/10)])\n",
    "sense = text_cleaner(sense[:int(len(sense)/10)])\n",
    "milton = text_cleaner(milton[:int(len(milton)/10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Raw:\n",
      " Book I Of Man's first disobedience, and the fruit Of that forbidden tree whose mortal taste Brought death into the World, and all our woe, With loss of Eden, till one greater Man Restore us, and regain the blissful seat, Sing, Heavenly Muse, that, on the secret top Of Oreb, or of Sinai, didst inspire That shepherd who first taught the chosen seed In the beginning how the heavens and earth Rose out of Chaos: or, if Sion hill Delight thee more, and Siloa's brook that flowed Fast by the oracle of G\n"
     ]
    }
   ],
   "source": [
    "# Print the first x characters of text\n",
    "print('\\nRaw:\\n', milton[0:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en')\n",
    "\n",
    "# All the processing work is done here, so it may take a while.\n",
    "alice_doc = nlp(alice)\n",
    "persuasion_doc = nlp(persuasion)\n",
    "sense_doc = nlp(sense)\n",
    "milton_doc = nlp(milton)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PERSON Alice\n",
      "DATE the hot day\n",
      "PERSON Alice\n",
      "PERSON Rabbit\n",
      "PERSON Rabbit\n",
      "PERSON Alice\n",
      "PERSON Alice\n",
      "PERSON Alice\n",
      "ORDINAL First\n",
      "CARDINAL one\n"
     ]
    }
   ],
   "source": [
    "# Extract the first ten entities.\n",
    "entities = list(alice_doc.ents)[0:10]\n",
    "for entity in entities:\n",
    "    print(entity.label_, ' '.join(t.orth_ for t in entity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(Alice, was, beginning, to, get, very, tired, ...</td>\n",
       "      <td>Carroll</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(So, she, was, considering, in, her, own, mind...</td>\n",
       "      <td>Carroll</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(There, was, nothing, so, VERY, remarkable, in...</td>\n",
       "      <td>Carroll</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(Oh, dear, !)</td>\n",
       "      <td>Carroll</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(Oh, dear, !)</td>\n",
       "      <td>Carroll</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0        1   2\n",
       "0  (Alice, was, beginning, to, get, very, tired, ...  Carroll  57\n",
       "1  (So, she, was, considering, in, her, own, mind...  Carroll  56\n",
       "2  (There, was, nothing, so, VERY, remarkable, in...  Carroll  27\n",
       "3                                      (Oh, dear, !)  Carroll   2\n",
       "4                                      (Oh, dear, !)  Carroll   2"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Group into sentences.\n",
    "alice_sents = [[sent, \"Carroll\",len([token for token in sent if not token.is_punct])] for sent in alice_doc.sents]\n",
    "persuasion_sents = [[sent, \"Austen\",len([token for token in sent if not token.is_punct])] for sent in persuasion_doc.sents]\n",
    "sense_sents = [[sent, \"Austen2\",len([token for token in sent if not token.is_punct])] for sent in sense_doc.sents]\n",
    "milton_sents = [[sent, \"Milton\",len([token for token in sent if not token.is_punct])] for sent in milton_doc.sents]\n",
    "\n",
    "# Combine the sentences from the four novels into one data frame.\n",
    "sentences = pd.DataFrame(alice_sents + persuasion_sents + sense_sents + milton_sents)\n",
    "sentences.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exclude stopwords and punctuation and use lemmas (root words) and limit to 1000 most common words for each text\n",
    "\n",
    "# Utility function to create a list of the 1000 most common words.\n",
    "def bag_of_words(text):\n",
    "    \n",
    "    # Filter out punctuation and stop words.\n",
    "    allwords = [token.lemma_\n",
    "                for token in text\n",
    "                if not token.is_punct\n",
    "                and not token.is_stop]\n",
    "    \n",
    "    # Return the most common words.\n",
    "    return [item[0] for item in Counter(allwords).most_common(1000)]\n",
    "    \n",
    "\n",
    "# Creates a data frame with features for each word in our common word set.\n",
    "# Each value is the count of the times the word appears in each sentence.\n",
    "def bow_features(sentences, common_words):\n",
    "    \n",
    "    # Scaffold the data frame and initialize counts to zero.\n",
    "    df = pd.DataFrame(columns=common_words)\n",
    "    df['text_sentence'] = sentences[0]\n",
    "    df['text_source'] = sentences[1]\n",
    "    df['words_per_sentence'] = sentences[2]\n",
    "    df.loc[:, common_words] = 0\n",
    "    \n",
    "    # Process each row, counting the occurrence of words in each sentence.\n",
    "    for i, sentence in enumerate(df['text_sentence']):\n",
    "        \n",
    "        # Convert the sentence to lemmas, then filter out punctuation,\n",
    "        # stop words, and uncommon words.\n",
    "        words = [token.lemma_\n",
    "                 for token in sentence\n",
    "                 if (\n",
    "                     not token.is_punct\n",
    "                     and not token.is_stop\n",
    "                     and token.lemma_ in common_words\n",
    "                 )]\n",
    "        \n",
    "        # Populate the row with word counts.\n",
    "        for word in words:\n",
    "            df.loc[i, word] += 1\n",
    "        \n",
    "        # This counter is just to make sure the kernel didn't hang.\n",
    "        if i % 50 == 0:\n",
    "            print(\"Processing row {}\".format(i))\n",
    "            \n",
    "    return df\n",
    "\n",
    "# Set up the bags.\n",
    "alicewords = bag_of_words(alice_doc)\n",
    "persuasionwords = bag_of_words(persuasion_doc)\n",
    "sensewords = bag_of_words(sense_doc)\n",
    "miltonwords = bag_of_words(milton_doc)\n",
    "\n",
    "# Combine bags to create a set of unique words.\n",
    "common_words = set(alicewords + persuasionwords + sensewords + miltonwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'approbation',\n",
       " 'hasten',\n",
       " 'eye',\n",
       " 'advise',\n",
       " 'alter',\n",
       " 'separation',\n",
       " 'discover',\n",
       " 'difficulty',\n",
       " 'household',\n",
       " 'chivalry',\n",
       " 'Confounded',\n",
       " 'pomp',\n",
       " 'singularity',\n",
       " 'inconvenience',\n",
       " \"know'st\",\n",
       " 'form',\n",
       " 'relish',\n",
       " 'headlong',\n",
       " 'suddenly',\n",
       " 'heave',\n",
       " 'accidentally',\n",
       " 'pin',\n",
       " 'ofttime',\n",
       " 'grief',\n",
       " 'Gloucester',\n",
       " 'pop',\n",
       " 'plainly',\n",
       " 'FOOT',\n",
       " 'bloom',\n",
       " 'transgress',\n",
       " 'county',\n",
       " 'humoured',\n",
       " 'Uppercross',\n",
       " 'despise',\n",
       " 'singe',\n",
       " 'comfortable',\n",
       " 'subterranean',\n",
       " 'strive',\n",
       " 'tone',\n",
       " 'connect',\n",
       " 'Walter',\n",
       " 'frost',\n",
       " 'extort',\n",
       " 'cherry',\n",
       " 'white',\n",
       " 'reasonably',\n",
       " 'mistress',\n",
       " 'seriously',\n",
       " 'calamity',\n",
       " 'foam',\n",
       " 'tall',\n",
       " 'blossom',\n",
       " 'revolve',\n",
       " 'instantly',\n",
       " 'assurance',\n",
       " 'especially',\n",
       " 'pine',\n",
       " 'White',\n",
       " 'help',\n",
       " 'conceive',\n",
       " 'village',\n",
       " 'wind',\n",
       " 'heavenly',\n",
       " 'noise',\n",
       " 'skurrie',\n",
       " 'discharge',\n",
       " 'truth',\n",
       " 'stir',\n",
       " 'grant',\n",
       " 'Titanian',\n",
       " 'relate',\n",
       " 'regulation',\n",
       " 'thought',\n",
       " 'troop',\n",
       " 'age',\n",
       " 'sign',\n",
       " 'requisition',\n",
       " 'high',\n",
       " 'fit',\n",
       " 'Mightiest',\n",
       " 'impenetrable',\n",
       " 'prudent',\n",
       " 'alloy',\n",
       " 'stay',\n",
       " 'remember',\n",
       " 'virtue',\n",
       " 'Jennings',\n",
       " 'race',\n",
       " '5',\n",
       " 'dwelling',\n",
       " 'tenant',\n",
       " 'ancient',\n",
       " 'denial',\n",
       " 'heir',\n",
       " 'shelf',\n",
       " 'allow',\n",
       " 'difference',\n",
       " 'Elliot',\n",
       " 'avoid',\n",
       " 'surprised',\n",
       " 'education',\n",
       " 'fact',\n",
       " 'economically',\n",
       " 'degradation',\n",
       " 'Anne',\n",
       " 'ungrateful',\n",
       " 'usually',\n",
       " 'death',\n",
       " 'notion',\n",
       " 'embarrassment',\n",
       " 'cousin',\n",
       " 'misery',\n",
       " 'proceed',\n",
       " 'steady',\n",
       " 'suppliant',\n",
       " '1785',\n",
       " 'completely',\n",
       " 'ancestry',\n",
       " 'enlarge',\n",
       " 'sooner',\n",
       " 'page',\n",
       " 'angry',\n",
       " 'Typhon',\n",
       " 'repress',\n",
       " 'toast',\n",
       " 'Egypt',\n",
       " 'Favoured',\n",
       " 'HALL',\n",
       " 'Latitude',\n",
       " 'bless',\n",
       " 'spire',\n",
       " 'enable',\n",
       " 'Dashwood',\n",
       " \"o'erpowere\",\n",
       " 'thrall',\n",
       " 'dislike',\n",
       " 'plain',\n",
       " 'doubtful',\n",
       " 'partiality',\n",
       " 'infernal',\n",
       " 'native',\n",
       " 'whirlwind',\n",
       " 'perfectly',\n",
       " 'youth',\n",
       " 'Serpent',\n",
       " 'want',\n",
       " 'shame',\n",
       " '1810',\n",
       " 'earthly',\n",
       " 'sister',\n",
       " 'distance',\n",
       " 'expedient',\n",
       " 'Mary',\n",
       " 'spot',\n",
       " 'sentence',\n",
       " 'se',\n",
       " 'mournful',\n",
       " 'London',\n",
       " 'entire',\n",
       " 'wander',\n",
       " 'real',\n",
       " 'fade',\n",
       " 'terror',\n",
       " 'contemptuously',\n",
       " 'curious',\n",
       " 'consciousness',\n",
       " 'draw',\n",
       " 'chief',\n",
       " 'sorrow',\n",
       " 'incapable',\n",
       " 'usual',\n",
       " 'show',\n",
       " \"mad'st\",\n",
       " 'rind',\n",
       " 'centre',\n",
       " 'rue',\n",
       " 'son',\n",
       " 'singleness',\n",
       " 'hold',\n",
       " 'beneath',\n",
       " 'instruction',\n",
       " 'husband',\n",
       " 'supernal',\n",
       " 'absurd',\n",
       " 'unconquerable',\n",
       " 'climb',\n",
       " 'town',\n",
       " 'message',\n",
       " 'dire',\n",
       " 'later',\n",
       " 'joy',\n",
       " 'suspicious',\n",
       " 'planning',\n",
       " 'forbearance',\n",
       " 'reproach',\n",
       " 'asunder',\n",
       " 'cultivate',\n",
       " 'fault',\n",
       " 'attempt',\n",
       " 'trouble',\n",
       " '2',\n",
       " 'assemble',\n",
       " 'civility',\n",
       " 'finally',\n",
       " 'entrail',\n",
       " 'dear',\n",
       " 'leave',\n",
       " 'manage',\n",
       " 'superior',\n",
       " 'unconsumed',\n",
       " 'carry',\n",
       " 'chamber',\n",
       " 'rat',\n",
       " 'rich',\n",
       " 'hall',\n",
       " 'end',\n",
       " 'intimacy',\n",
       " 'acquaint',\n",
       " 'die',\n",
       " 'opportunity',\n",
       " 'bright',\n",
       " 'cheerfulness',\n",
       " 'quick',\n",
       " 'edge',\n",
       " 'justly',\n",
       " 'ear',\n",
       " 'mean',\n",
       " 'insufficient',\n",
       " 'addition',\n",
       " 'Mammon',\n",
       " 'severely',\n",
       " 'visitor',\n",
       " 'black',\n",
       " 'trot',\n",
       " 'spiritless',\n",
       " 'skiff',\n",
       " 'kind',\n",
       " 'anger',\n",
       " 'experience',\n",
       " 'suitable',\n",
       " 'tempestuous',\n",
       " 'pavement',\n",
       " 'week',\n",
       " 'bellow',\n",
       " 'disappointment',\n",
       " 'uneventful',\n",
       " 'constant',\n",
       " '15',\n",
       " 'prescribe',\n",
       " 'task',\n",
       " 'map',\n",
       " 'sick',\n",
       " 'wonder',\n",
       " 'shrink',\n",
       " 'Tarsus',\n",
       " 'read',\n",
       " 'brave',\n",
       " 'convenience',\n",
       " 'indelicacy',\n",
       " 'militate',\n",
       " 'noon',\n",
       " 'infirmity',\n",
       " 'lee',\n",
       " '9',\n",
       " 'Baldwin',\n",
       " 'expedition',\n",
       " 'Taunton',\n",
       " 'timid',\n",
       " 'wrath',\n",
       " 'Esq',\n",
       " 'hugest',\n",
       " 'rage',\n",
       " 'Commander',\n",
       " 'strongly',\n",
       " 'survive',\n",
       " 'presently',\n",
       " 'dwell',\n",
       " 'scanty',\n",
       " 'common',\n",
       " 'separate',\n",
       " 'shield',\n",
       " 'Prone',\n",
       " 'society',\n",
       " 'sybstance',\n",
       " 'averted',\n",
       " 'inclination',\n",
       " 'deed',\n",
       " 'close',\n",
       " 'Instruct',\n",
       " 'bequest',\n",
       " 'darken',\n",
       " 'visible',\n",
       " 'bat',\n",
       " 'shrubbery',\n",
       " 'bleed',\n",
       " 'Cherubim',\n",
       " 'cunning',\n",
       " 'seaman',\n",
       " 'bring',\n",
       " 'tire',\n",
       " 'favourite',\n",
       " 'visit',\n",
       " 'connoisseur',\n",
       " 'unhappy',\n",
       " 'provoke',\n",
       " 'creator',\n",
       " 'expand',\n",
       " 'Farewell',\n",
       " 'sad',\n",
       " 'rational',\n",
       " 'hearted',\n",
       " 'originally',\n",
       " 'composure',\n",
       " 'th',\n",
       " 'fierce',\n",
       " 'devise',\n",
       " 'connexion',\n",
       " 'remarkably',\n",
       " 'Strength',\n",
       " 'continuance',\n",
       " 'syrian',\n",
       " 'DRINK',\n",
       " 'perform',\n",
       " 'trifling',\n",
       " 'boot',\n",
       " 'spake',\n",
       " 'celestial',\n",
       " 'aught',\n",
       " 'able',\n",
       " 'billow',\n",
       " 'inch',\n",
       " 'blow',\n",
       " 'service',\n",
       " 'fury',\n",
       " 'paragraph',\n",
       " 'clime',\n",
       " 'consult',\n",
       " 'awful',\n",
       " 'fair',\n",
       " 'earnestness',\n",
       " 'turkey',\n",
       " 'welcome',\n",
       " 'smoke',\n",
       " 'mineral',\n",
       " 'mind',\n",
       " 'provision',\n",
       " 'curtain',\n",
       " 'tradespeople',\n",
       " 'believe',\n",
       " 'directly',\n",
       " 'valley',\n",
       " 'Palestine',\n",
       " 'severe',\n",
       " 'regular',\n",
       " 'pink',\n",
       " 'reach',\n",
       " 'admiral',\n",
       " 'talent',\n",
       " 'take',\n",
       " 'mile',\n",
       " 'finger',\n",
       " 'early',\n",
       " 'courage',\n",
       " 'Thick',\n",
       " 'sulphurous',\n",
       " 'imprudence',\n",
       " 'sixpence',\n",
       " 'trick',\n",
       " 'avail',\n",
       " 'outline',\n",
       " 'line',\n",
       " 'happy',\n",
       " 'dressed',\n",
       " 'instead',\n",
       " 'learn',\n",
       " 'transmit',\n",
       " 'likewise',\n",
       " 'roam',\n",
       " 'romantic',\n",
       " 'little',\n",
       " 'pool',\n",
       " 'correct',\n",
       " 'merely',\n",
       " 'temper',\n",
       " 'stock',\n",
       " 'toffee',\n",
       " 'degrade',\n",
       " 'region',\n",
       " 'wave',\n",
       " 'malice',\n",
       " 'measure',\n",
       " 'amply',\n",
       " 'mild',\n",
       " 'alarm',\n",
       " 'plenty',\n",
       " 'exist',\n",
       " 'sacrifice',\n",
       " 'jump',\n",
       " 'stout',\n",
       " 'deem',\n",
       " 'healthy',\n",
       " 'circle',\n",
       " 'park',\n",
       " 'stand',\n",
       " 'English',\n",
       " 'fine',\n",
       " 'endless',\n",
       " 'utility',\n",
       " 'industrious',\n",
       " 'Middletons',\n",
       " 'rite',\n",
       " 'pause',\n",
       " 'descent',\n",
       " 'choose',\n",
       " 'sufferance',\n",
       " 'chaise',\n",
       " 'mama',\n",
       " 'curtseying',\n",
       " 'confidential',\n",
       " 'idol',\n",
       " 'post',\n",
       " 'purchase',\n",
       " 'hear',\n",
       " 'gate',\n",
       " 'keep',\n",
       " 'impetuous',\n",
       " 'prostrate',\n",
       " 'ken',\n",
       " 'endanger',\n",
       " 'pronounce',\n",
       " 'door',\n",
       " 'unnecessary',\n",
       " 'alteration',\n",
       " 'perpetuate',\n",
       " 'sovereign',\n",
       " 'HEARTHRUG',\n",
       " 'charitable',\n",
       " 'honour',\n",
       " 'possess',\n",
       " 'nature',\n",
       " 'creation',\n",
       " 'art',\n",
       " 'consistent',\n",
       " 'stretch',\n",
       " 'arrangement',\n",
       " 'continual',\n",
       " 'fame',\n",
       " 'boundless',\n",
       " 'Mr.',\n",
       " 'estate',\n",
       " 'consolation',\n",
       " 'sulphur',\n",
       " 'storm',\n",
       " 'beautifully',\n",
       " 'establishment',\n",
       " 'Dashwoods',\n",
       " 'lot',\n",
       " 'alas',\n",
       " 'child',\n",
       " 'connection',\n",
       " 'let',\n",
       " 'grim',\n",
       " 'part',\n",
       " 'reigning',\n",
       " 'flash',\n",
       " 'seldom',\n",
       " 'feel',\n",
       " 'WAISTCOAT',\n",
       " 'wile',\n",
       " 'Henry',\n",
       " 'superannuated',\n",
       " 'scruple',\n",
       " 'armed',\n",
       " 'unworthy',\n",
       " 'shake',\n",
       " 'body',\n",
       " 'II',\n",
       " 'astounded',\n",
       " 'income',\n",
       " 'knock',\n",
       " 'lose',\n",
       " 'precisely',\n",
       " 'everybody',\n",
       " 'glory',\n",
       " 'carrier',\n",
       " 'proof',\n",
       " 'unfeeling',\n",
       " 'certainly',\n",
       " 'wild',\n",
       " 'join',\n",
       " 'selfish',\n",
       " 'totally',\n",
       " 'confine',\n",
       " 'vanish',\n",
       " 'curiosity',\n",
       " 'opening',\n",
       " 'goodness',\n",
       " 'overhead',\n",
       " 'awake',\n",
       " 'fix',\n",
       " 'cell',\n",
       " 'Archangel',\n",
       " 'horrible',\n",
       " 'Angel',\n",
       " 'excursion',\n",
       " 'zealous',\n",
       " 'Sat',\n",
       " 'mankind',\n",
       " 'naturally',\n",
       " 'attraction',\n",
       " 'charge',\n",
       " 'apple',\n",
       " 'impoverish',\n",
       " 'flavour',\n",
       " 'opposite',\n",
       " 'disgust',\n",
       " 'self',\n",
       " 'serve',\n",
       " 'stop',\n",
       " 'old',\n",
       " 'scene',\n",
       " 'beautiful',\n",
       " 'preference',\n",
       " 'indication',\n",
       " 'print',\n",
       " 'pit',\n",
       " 'finale',\n",
       " 'conceal',\n",
       " 'respectable',\n",
       " 'entrance',\n",
       " 'Almighty',\n",
       " 'responsible',\n",
       " 'wish',\n",
       " 'counsellor',\n",
       " 'indulge',\n",
       " 'dejection',\n",
       " 'accord',\n",
       " 'hospitality',\n",
       " 'King',\n",
       " 'sole',\n",
       " 'school',\n",
       " 'reign',\n",
       " 'look',\n",
       " 'considerable',\n",
       " 'John',\n",
       " 'wage',\n",
       " 'guile',\n",
       " 'push',\n",
       " 'lamp',\n",
       " 'property',\n",
       " 'rejoice',\n",
       " \"sat'st\",\n",
       " 'Foe',\n",
       " 'ought',\n",
       " 'House',\n",
       " 'poison',\n",
       " 'begin',\n",
       " 'straight',\n",
       " 'prepare',\n",
       " 'comprehend',\n",
       " 'naval',\n",
       " 'shut',\n",
       " 'mother',\n",
       " 'man',\n",
       " 'suitably',\n",
       " 'offer',\n",
       " 'fully',\n",
       " 'custard',\n",
       " 'ready',\n",
       " 'doubt',\n",
       " 'increase',\n",
       " 'preside',\n",
       " 'funny',\n",
       " 'barouche',\n",
       " 'play',\n",
       " 'Deep',\n",
       " 'advice',\n",
       " 'kid',\n",
       " \"o'erwhelmed\",\n",
       " 'gratitude',\n",
       " 'mansion',\n",
       " 'hurt',\n",
       " 'compact',\n",
       " 'daughter',\n",
       " 'confide',\n",
       " 'penetration',\n",
       " 'intimate',\n",
       " 'stream',\n",
       " 'maid',\n",
       " 'word',\n",
       " 'stench',\n",
       " 'shew',\n",
       " 'introduce',\n",
       " 'safe',\n",
       " 'Croft',\n",
       " 'pride',\n",
       " 'urgency',\n",
       " 'recess',\n",
       " 'wit',\n",
       " 'doze',\n",
       " 'succession',\n",
       " 'uncle',\n",
       " 'repair',\n",
       " 'rule',\n",
       " 'credit',\n",
       " 'promise',\n",
       " 'wing',\n",
       " 'artificial',\n",
       " 'model',\n",
       " 'study',\n",
       " 'loud',\n",
       " 'lock',\n",
       " 'rear',\n",
       " 'life',\n",
       " 'seduce',\n",
       " 'performance',\n",
       " 'solicit',\n",
       " 'long',\n",
       " 'hopeless',\n",
       " 'subject',\n",
       " 'Stanhill',\n",
       " 'box',\n",
       " 'short',\n",
       " 'unlike',\n",
       " 'tart',\n",
       " 'Sir',\n",
       " 'charm',\n",
       " 'shed',\n",
       " 'extremely',\n",
       " 'accomplishment',\n",
       " 'properly',\n",
       " 'true',\n",
       " 'sound',\n",
       " 'fiery',\n",
       " 'successful',\n",
       " 'honest',\n",
       " 'Mrs',\n",
       " 'opinion',\n",
       " 'minute',\n",
       " 'importance',\n",
       " 'bid',\n",
       " 'Stevenson',\n",
       " 'Lady',\n",
       " 'hath',\n",
       " 'send',\n",
       " 'proud',\n",
       " 'vengeance',\n",
       " 'aspire',\n",
       " 'Lay',\n",
       " 'accommodate',\n",
       " 'Lodge',\n",
       " 'twice',\n",
       " 'small',\n",
       " 'profoundest',\n",
       " 'Seraphic',\n",
       " 'piece',\n",
       " 'unjust',\n",
       " 'duty',\n",
       " 'letter',\n",
       " 'fly',\n",
       " 'bequeath',\n",
       " 'alienable',\n",
       " 'propriety',\n",
       " 'maintenance',\n",
       " 'enter',\n",
       " 'window',\n",
       " 'band',\n",
       " 'calculation',\n",
       " 'alike',\n",
       " 'publicly',\n",
       " 'populous',\n",
       " 'Muse',\n",
       " 'gallon',\n",
       " 'cheap',\n",
       " 'transcendent',\n",
       " 'uninteresting',\n",
       " 'justify',\n",
       " 'Man',\n",
       " 'legion',\n",
       " 'intend',\n",
       " 'indulgence',\n",
       " 'rouse',\n",
       " 'woe',\n",
       " 'elegance',\n",
       " 'actually',\n",
       " 'ardour',\n",
       " 'disdain',\n",
       " 'method',\n",
       " 'conclude',\n",
       " 'announce',\n",
       " 'access',\n",
       " 'united',\n",
       " 'generally',\n",
       " 'fellow',\n",
       " 'interesting',\n",
       " 'relationship',\n",
       " 'privilege',\n",
       " 'vain',\n",
       " 'overthrow',\n",
       " 'Power',\n",
       " 'frequent',\n",
       " 'fate',\n",
       " 'warmth',\n",
       " 'habit',\n",
       " 'friendship',\n",
       " 'breathe',\n",
       " 'indecorous',\n",
       " 'womb',\n",
       " 'satisfied',\n",
       " 'abroad',\n",
       " 'mercy',\n",
       " 'apparently',\n",
       " 'see',\n",
       " 'occasional',\n",
       " 'intelligence',\n",
       " 'suppose',\n",
       " 'compromise',\n",
       " 'disturb',\n",
       " 'downfall',\n",
       " \"o'er\",\n",
       " 'slip',\n",
       " 'estimate',\n",
       " 'overcome',\n",
       " 'holy',\n",
       " 'possession',\n",
       " 'flow',\n",
       " 'Park',\n",
       " 'probability',\n",
       " 'quietness',\n",
       " 'mix',\n",
       " 'poor',\n",
       " 'ore',\n",
       " 'grieve',\n",
       " 'liberality',\n",
       " 'bottomless',\n",
       " 'dispose',\n",
       " 'volume',\n",
       " 'description',\n",
       " 'revolt',\n",
       " 'diminish',\n",
       " 'anticipate',\n",
       " 'lessen',\n",
       " 'forbidden',\n",
       " 'endeavor',\n",
       " 'catch',\n",
       " 'disapprove',\n",
       " 'stocking',\n",
       " 'follow',\n",
       " 'marry',\n",
       " 'humored',\n",
       " 'ask',\n",
       " 'resist',\n",
       " 'outward',\n",
       " 'payment',\n",
       " 'somebody',\n",
       " 'New',\n",
       " 'home',\n",
       " 'glorious',\n",
       " 'repulse',\n",
       " 'agreeable',\n",
       " 'fountain',\n",
       " 'Cowper',\n",
       " 'convince',\n",
       " 'eternal',\n",
       " 'omnipotent',\n",
       " 'December',\n",
       " 'strange',\n",
       " 'amazed',\n",
       " 'strength',\n",
       " 'battle',\n",
       " 'Enemy',\n",
       " 'happening',\n",
       " 'impious',\n",
       " 'breeding',\n",
       " 'explanation',\n",
       " 'comprehensive',\n",
       " 'Bath',\n",
       " 'ladyship',\n",
       " 'image',\n",
       " 'give',\n",
       " 'reserve',\n",
       " 'singular',\n",
       " 'hideous',\n",
       " 'Captain',\n",
       " 'disrespectfully',\n",
       " 'candle',\n",
       " 'anne',\n",
       " 'affection',\n",
       " 'Dugdale',\n",
       " 'odd',\n",
       " 'forthwith',\n",
       " 'scape',\n",
       " 'journey',\n",
       " 'Siloa',\n",
       " 'unconnected',\n",
       " 'generous',\n",
       " 'rood',\n",
       " 'female',\n",
       " 'gentle',\n",
       " 'introduction',\n",
       " 'neck',\n",
       " 'vengeful',\n",
       " 'heat',\n",
       " 'twelvemonth',\n",
       " 'understanding',\n",
       " 'deify',\n",
       " 'fail',\n",
       " 'clear',\n",
       " 'effect',\n",
       " 'Heap',\n",
       " 'torment',\n",
       " 'lover',\n",
       " 'run',\n",
       " 'mouse',\n",
       " 'contemplate',\n",
       " 'overpower',\n",
       " 'skilful',\n",
       " 'Duchess',\n",
       " 'James',\n",
       " 'deal',\n",
       " 'enemy',\n",
       " 'esteem',\n",
       " 'Delight',\n",
       " 'eager',\n",
       " 'conduct',\n",
       " 'need',\n",
       " 'doleful',\n",
       " 'amazing',\n",
       " 'mate',\n",
       " 'outshine',\n",
       " 'flower',\n",
       " 'offence',\n",
       " 'currant',\n",
       " 'unwelcome',\n",
       " 'thank',\n",
       " 'foe',\n",
       " 'exert',\n",
       " 'proper',\n",
       " 'century',\n",
       " 'trial',\n",
       " 'weak',\n",
       " 'represent',\n",
       " 'hue',\n",
       " 'flannel',\n",
       " 'cake',\n",
       " 'sue',\n",
       " 'swim',\n",
       " 'observe',\n",
       " 'conversation',\n",
       " 'reason',\n",
       " 'aware',\n",
       " 'forcibly',\n",
       " 'Hall',\n",
       " 'repent',\n",
       " 'portion',\n",
       " 'article',\n",
       " 'fire',\n",
       " 'crime',\n",
       " 'exceedingly',\n",
       " 'lost',\n",
       " 'source',\n",
       " 'sixteen',\n",
       " 'pretty',\n",
       " 'sensibility',\n",
       " 'wherefore',\n",
       " 'brightness',\n",
       " 'monstrous',\n",
       " 'thunder',\n",
       " 'difficult',\n",
       " 'delicate',\n",
       " 'undesirableness',\n",
       " 'flat',\n",
       " 'burn',\n",
       " 'spirit',\n",
       " 'associate',\n",
       " 'label',\n",
       " 'improvement',\n",
       " 'massy',\n",
       " 'sitting',\n",
       " 'duodecimo',\n",
       " 'question',\n",
       " 'hang',\n",
       " 'keen',\n",
       " 'reigh',\n",
       " 'hardly',\n",
       " \"whate'er\",\n",
       " 'constantly',\n",
       " 'stately',\n",
       " 'good',\n",
       " 'implicit',\n",
       " 'complete',\n",
       " 'tie',\n",
       " 'countenance',\n",
       " 'widow',\n",
       " 'smooth',\n",
       " 'chapter',\n",
       " 'prey',\n",
       " 'resolution',\n",
       " 'nervous',\n",
       " 'Antipathies',\n",
       " 'destine',\n",
       " 'rank',\n",
       " 'loyalty',\n",
       " 'garden',\n",
       " 'soft',\n",
       " 'point',\n",
       " 'period',\n",
       " 'add',\n",
       " 'prospect',\n",
       " 'violent',\n",
       " 'accommodation',\n",
       " 'idea',\n",
       " 'understand',\n",
       " 'beast',\n",
       " 'fall',\n",
       " 'restriction',\n",
       " 'denote',\n",
       " 'housekeeper',\n",
       " 'beginning',\n",
       " 'arrival',\n",
       " 'board',\n",
       " 'heaven',\n",
       " 'extent',\n",
       " 'uphold',\n",
       " 'ashamed',\n",
       " 'gentleman',\n",
       " 'unite',\n",
       " 'vision',\n",
       " 'banish',\n",
       " 'dark',\n",
       " 'rely',\n",
       " 'music',\n",
       " 'silly',\n",
       " 'legacy',\n",
       " 'parting',\n",
       " 'case',\n",
       " 'entreaty',\n",
       " 'event',\n",
       " 'agony',\n",
       " 'authority',\n",
       " 'pleasing',\n",
       " 'teach',\n",
       " 'dining',\n",
       " 'blush',\n",
       " 'simple',\n",
       " 'aonian',\n",
       " 'occupation',\n",
       " 'anon',\n",
       " 'apt',\n",
       " 'benevolent',\n",
       " 'parent',\n",
       " '1784',\n",
       " 'cover',\n",
       " 'tame',\n",
       " 'sense',\n",
       " 'feature',\n",
       " 'desire',\n",
       " 'oracle',\n",
       " 'possible',\n",
       " 'tempt',\n",
       " 'cat',\n",
       " 'flamed',\n",
       " 'blissful',\n",
       " 'hand',\n",
       " 'Hurled',\n",
       " 'rumour',\n",
       " 'contrast',\n",
       " 'whereto',\n",
       " 'tend',\n",
       " 'wanton',\n",
       " 'obdurate',\n",
       " 'huge',\n",
       " 'character',\n",
       " 'unattempted',\n",
       " 'finish',\n",
       " 'Anon',\n",
       " 'value',\n",
       " 'eligible',\n",
       " 'comfortably',\n",
       " 'applicant',\n",
       " 'recall',\n",
       " 'discern',\n",
       " 'apostate',\n",
       " 'lie',\n",
       " 'tell',\n",
       " 'reiterate',\n",
       " 'strictly',\n",
       " 'fond',\n",
       " 'Barton',\n",
       " 'dream',\n",
       " 'number',\n",
       " 'mainly',\n",
       " 'complain',\n",
       " 'neighbourly',\n",
       " 'claim',\n",
       " 'reality',\n",
       " 'pity',\n",
       " 'supreme',\n",
       " 'consideration',\n",
       " 'contraction',\n",
       " ...}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "common_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing row 0\n",
      "Processing row 50\n",
      "Processing row 100\n",
      "Processing row 150\n",
      "Processing row 200\n",
      "Processing row 250\n",
      "Processing row 300\n",
      "Processing row 350\n",
      "Processing row 400\n",
      "Processing row 450\n",
      "Processing row 500\n",
      "Processing row 550\n",
      "Processing row 600\n",
      "Processing row 650\n",
      "Processing row 700\n",
      "Processing row 750\n",
      "Processing row 800\n",
      "Processing row 850\n",
      "Processing row 900\n",
      "Processing row 950\n",
      "Processing row 1000\n",
      "Processing row 1050\n",
      "Processing row 1100\n",
      "Processing row 1150\n",
      "Processing row 1200\n",
      "Processing row 1250\n",
      "Processing row 1300\n",
      "Processing row 1350\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>approbation</th>\n",
       "      <th>hasten</th>\n",
       "      <th>eye</th>\n",
       "      <th>advise</th>\n",
       "      <th>alter</th>\n",
       "      <th>separation</th>\n",
       "      <th>discover</th>\n",
       "      <th>difficulty</th>\n",
       "      <th>household</th>\n",
       "      <th>chivalry</th>\n",
       "      <th>...</th>\n",
       "      <th>November</th>\n",
       "      <th>unheard</th>\n",
       "      <th>handsome</th>\n",
       "      <th>unusual</th>\n",
       "      <th>speedily</th>\n",
       "      <th>revive</th>\n",
       "      <th>size</th>\n",
       "      <th>text_sentence</th>\n",
       "      <th>text_source</th>\n",
       "      <th>words_per_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(Alice, was, beginning, to, get, very, tired, ...</td>\n",
       "      <td>Carroll</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(So, she, was, considering, in, her, own, mind...</td>\n",
       "      <td>Carroll</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(There, was, nothing, so, VERY, remarkable, in...</td>\n",
       "      <td>Carroll</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(Oh, dear, !)</td>\n",
       "      <td>Carroll</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(Oh, dear, !)</td>\n",
       "      <td>Carroll</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2488 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   approbation  hasten  eye  advise  alter  separation  discover  difficulty  \\\n",
       "0            0       0    0       0      0           0         0           0   \n",
       "1            0       0    1       0      0           0         0           0   \n",
       "2            0       0    0       0      0           0         0           0   \n",
       "3            0       0    0       0      0           0         0           0   \n",
       "4            0       0    0       0      0           0         0           0   \n",
       "\n",
       "   household  chivalry  ...  November  unheard  handsome  unusual  speedily  \\\n",
       "0          0         0  ...         0        0         0        0         0   \n",
       "1          0         0  ...         0        0         0        0         0   \n",
       "2          0         0  ...         0        0         0        0         0   \n",
       "3          0         0  ...         0        0         0        0         0   \n",
       "4          0         0  ...         0        0         0        0         0   \n",
       "\n",
       "   revive  size                                      text_sentence  \\\n",
       "0       0     0  (Alice, was, beginning, to, get, very, tired, ...   \n",
       "1       0     0  (So, she, was, considering, in, her, own, mind...   \n",
       "2       0     0  (There, was, nothing, so, VERY, remarkable, in...   \n",
       "3       0     0                                      (Oh, dear, !)   \n",
       "4       0     0                                      (Oh, dear, !)   \n",
       "\n",
       "   text_source  words_per_sentence  \n",
       "0      Carroll                  57  \n",
       "1      Carroll                  56  \n",
       "2      Carroll                  27  \n",
       "3      Carroll                   2  \n",
       "4      Carroll                   2  \n",
       "\n",
       "[5 rows x 2488 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create our data frame with features. This can take a while to run.\n",
    "word_counts = bow_features(sentences, common_words)\n",
    "word_counts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(825, 2486) (825,)\n",
      "Training set score: 0.9163636363636364\n",
      "\n",
      "Test set score: 0.7618181818181818\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "Y = word_counts['text_source']\n",
    "X = np.array(word_counts.drop(['text_sentence','text_source'], 1))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    Y,\n",
    "                                                    test_size=0.4,\n",
    "                                                    random_state=0)\n",
    "\n",
    "lr = LogisticRegression(penalty='l2')\n",
    "\n",
    "train = lr.fit(X_train, y_train)\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print('Training set score:', lr.score(X_train, y_train))\n",
    "print('\\nTest set score:', lr.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, adding number of words per sentence, the test set score is greatly improve\n",
    "The training score declined slightly  - try making the overall set bigger - back to 2000 common words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exclude stopwords and punctuation and use lemmas (root words) and limit to 2000 most common words for each text\n",
    "\n",
    "# Utility function to create a list of the 2000 most common words.\n",
    "def bag_of_words(text):\n",
    "    \n",
    "    # Filter out punctuation and stop words.\n",
    "    allwords = [token.lemma_\n",
    "                for token in text\n",
    "                if not token.is_punct\n",
    "                and not token.is_stop]\n",
    "    \n",
    "    # Return the most common words.\n",
    "    return [item[0] for item in Counter(allwords).most_common(2000)]\n",
    "    \n",
    "\n",
    "# Creates a data frame with features for each word in our common word set.\n",
    "# Each value is the count of the times the word appears in each sentence.\n",
    "def bow_features(sentences, common_words):\n",
    "    \n",
    "    # Scaffold the data frame and initialize counts to zero.\n",
    "    df = pd.DataFrame(columns=common_words)\n",
    "    df['text_sentence'] = sentences[0]\n",
    "    df['text_source'] = sentences[1]\n",
    "    df['words_per_sentence'] = sentences[2]\n",
    "    df.loc[:, common_words] = 0\n",
    "    \n",
    "    # Process each row, counting the occurrence of words in each sentence.\n",
    "    for i, sentence in enumerate(df['text_sentence']):\n",
    "        \n",
    "        # Convert the sentence to lemmas, then filter out punctuation,\n",
    "        # stop words, and uncommon words.\n",
    "        words = [token.lemma_\n",
    "                 for token in sentence\n",
    "                 if (\n",
    "                     not token.is_punct\n",
    "                     and not token.is_stop\n",
    "                     and token.lemma_ in common_words\n",
    "                 )]\n",
    "        \n",
    "        # Populate the row with word counts.\n",
    "        for word in words:\n",
    "            df.loc[i, word] += 1\n",
    "        \n",
    "        # This counter is just to make sure the kernel didn't hang.\n",
    "        if i % 50 == 0:\n",
    "            print(\"Processing row {}\".format(i))\n",
    "            \n",
    "    return df\n",
    "\n",
    "# Set up the bags.\n",
    "alicewords = bag_of_words(alice_doc)\n",
    "persuasionwords = bag_of_words(persuasion_doc)\n",
    "sensewords = bag_of_words(sense_doc)\n",
    "miltonwords = bag_of_words(milton_doc)\n",
    "\n",
    "# Combine bags to create a set of unique words.\n",
    "common_words = set(alicewords + persuasionwords + sensewords + miltonwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing row 0\n",
      "Processing row 50\n",
      "Processing row 100\n",
      "Processing row 150\n",
      "Processing row 200\n",
      "Processing row 250\n",
      "Processing row 300\n",
      "Processing row 350\n",
      "Processing row 400\n",
      "Processing row 450\n",
      "Processing row 500\n",
      "Processing row 550\n",
      "Processing row 600\n",
      "Processing row 650\n",
      "Processing row 700\n",
      "Processing row 750\n",
      "Processing row 800\n",
      "Processing row 850\n",
      "Processing row 900\n",
      "Processing row 950\n",
      "Processing row 1000\n",
      "Processing row 1050\n",
      "Processing row 1100\n",
      "Processing row 1150\n",
      "Processing row 1200\n",
      "Processing row 1250\n",
      "Processing row 1300\n",
      "Processing row 1350\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>approbation</th>\n",
       "      <th>excellence</th>\n",
       "      <th>hasten</th>\n",
       "      <th>underneath</th>\n",
       "      <th>eye</th>\n",
       "      <th>advise</th>\n",
       "      <th>Horonaim</th>\n",
       "      <th>crystal</th>\n",
       "      <th>alter</th>\n",
       "      <th>separation</th>\n",
       "      <th>...</th>\n",
       "      <th>parlor</th>\n",
       "      <th>orgy</th>\n",
       "      <th>organ</th>\n",
       "      <th>speedily</th>\n",
       "      <th>revive</th>\n",
       "      <th>Damascus</th>\n",
       "      <th>size</th>\n",
       "      <th>text_sentence</th>\n",
       "      <th>text_source</th>\n",
       "      <th>words_per_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(Alice, was, beginning, to, get, very, tired, ...</td>\n",
       "      <td>Carroll</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(So, she, was, considering, in, her, own, mind...</td>\n",
       "      <td>Carroll</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(There, was, nothing, so, VERY, remarkable, in...</td>\n",
       "      <td>Carroll</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(Oh, dear, !)</td>\n",
       "      <td>Carroll</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(Oh, dear, !)</td>\n",
       "      <td>Carroll</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 3835 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   approbation  excellence  hasten  underneath  eye  advise  Horonaim  \\\n",
       "0            0           0       0           0    0       0         0   \n",
       "1            0           0       0           0    1       0         0   \n",
       "2            0           0       0           0    0       0         0   \n",
       "3            0           0       0           0    0       0         0   \n",
       "4            0           0       0           0    0       0         0   \n",
       "\n",
       "   crystal  alter  separation  ...  parlor  orgy  organ  speedily  revive  \\\n",
       "0        0      0           0  ...       0     0      0         0       0   \n",
       "1        0      0           0  ...       0     0      0         0       0   \n",
       "2        0      0           0  ...       0     0      0         0       0   \n",
       "3        0      0           0  ...       0     0      0         0       0   \n",
       "4        0      0           0  ...       0     0      0         0       0   \n",
       "\n",
       "   Damascus  size                                      text_sentence  \\\n",
       "0         0     0  (Alice, was, beginning, to, get, very, tired, ...   \n",
       "1         0     0  (So, she, was, considering, in, her, own, mind...   \n",
       "2         0     0  (There, was, nothing, so, VERY, remarkable, in...   \n",
       "3         0     0                                      (Oh, dear, !)   \n",
       "4         0     0                                      (Oh, dear, !)   \n",
       "\n",
       "   text_source  words_per_sentence  \n",
       "0      Carroll                  57  \n",
       "1      Carroll                  56  \n",
       "2      Carroll                  27  \n",
       "3      Carroll                   2  \n",
       "4      Carroll                   2  \n",
       "\n",
       "[5 rows x 3835 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create our data frame with features. This can take a while to run.\n",
    "word_counts = bow_features(sentences, common_words)\n",
    "word_counts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1100, 3833) (1100,)\n",
      "Training set score: 0.9281818181818182\n",
      "\n",
      "Test set score: 0.7563636363636363\n"
     ]
    }
   ],
   "source": [
    "# Also, adjust test size\n",
    "\n",
    "Y = word_counts['text_source']\n",
    "X = np.array(word_counts.drop(['text_sentence','text_source'], 1))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    Y,\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=0)\n",
    "\n",
    "lr = LogisticRegression(penalty='l2')\n",
    "\n",
    "train = lr.fit(X_train, y_train)\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print('Training set score:', lr.score(X_train, y_train))\n",
    "print('\\nTest set score:', lr.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is very similar result to first so additional common words do not seem necessary to produce a substantially similar result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
